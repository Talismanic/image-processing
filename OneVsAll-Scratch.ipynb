{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "757568cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15.26</td>\n",
       "      <td>14.84</td>\n",
       "      <td>0.8710</td>\n",
       "      <td>5.763</td>\n",
       "      <td>3.312</td>\n",
       "      <td>2.221</td>\n",
       "      <td>5.220</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14.88</td>\n",
       "      <td>14.57</td>\n",
       "      <td>0.8811</td>\n",
       "      <td>5.554</td>\n",
       "      <td>3.333</td>\n",
       "      <td>1.018</td>\n",
       "      <td>4.956</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14.29</td>\n",
       "      <td>14.09</td>\n",
       "      <td>0.9050</td>\n",
       "      <td>5.291</td>\n",
       "      <td>3.337</td>\n",
       "      <td>2.699</td>\n",
       "      <td>4.825</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13.84</td>\n",
       "      <td>13.94</td>\n",
       "      <td>0.8955</td>\n",
       "      <td>5.324</td>\n",
       "      <td>3.379</td>\n",
       "      <td>2.259</td>\n",
       "      <td>4.805</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16.14</td>\n",
       "      <td>14.99</td>\n",
       "      <td>0.9034</td>\n",
       "      <td>5.658</td>\n",
       "      <td>3.562</td>\n",
       "      <td>1.355</td>\n",
       "      <td>5.175</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>14.38</td>\n",
       "      <td>14.21</td>\n",
       "      <td>0.8951</td>\n",
       "      <td>5.386</td>\n",
       "      <td>3.312</td>\n",
       "      <td>2.462</td>\n",
       "      <td>4.956</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>14.69</td>\n",
       "      <td>14.49</td>\n",
       "      <td>0.8799</td>\n",
       "      <td>5.563</td>\n",
       "      <td>3.259</td>\n",
       "      <td>3.586</td>\n",
       "      <td>5.219</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>14.11</td>\n",
       "      <td>14.10</td>\n",
       "      <td>0.8911</td>\n",
       "      <td>5.420</td>\n",
       "      <td>3.302</td>\n",
       "      <td>2.700</td>\n",
       "      <td>5.000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>16.63</td>\n",
       "      <td>15.46</td>\n",
       "      <td>0.8747</td>\n",
       "      <td>6.053</td>\n",
       "      <td>3.465</td>\n",
       "      <td>2.040</td>\n",
       "      <td>5.877</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>16.44</td>\n",
       "      <td>15.25</td>\n",
       "      <td>0.8880</td>\n",
       "      <td>5.884</td>\n",
       "      <td>3.505</td>\n",
       "      <td>1.969</td>\n",
       "      <td>5.533</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       0      1       2      3      4      5      6  7\n",
       "0  15.26  14.84  0.8710  5.763  3.312  2.221  5.220  1\n",
       "1  14.88  14.57  0.8811  5.554  3.333  1.018  4.956  1\n",
       "2  14.29  14.09  0.9050  5.291  3.337  2.699  4.825  1\n",
       "3  13.84  13.94  0.8955  5.324  3.379  2.259  4.805  1\n",
       "4  16.14  14.99  0.9034  5.658  3.562  1.355  5.175  1\n",
       "5  14.38  14.21  0.8951  5.386  3.312  2.462  4.956  1\n",
       "6  14.69  14.49  0.8799  5.563  3.259  3.586  5.219  1\n",
       "7  14.11  14.10  0.8911  5.420  3.302  2.700  5.000  1\n",
       "8  16.63  15.46  0.8747  6.053  3.465  2.040  5.877  1\n",
       "9  16.44  15.25  0.8880  5.884  3.505  1.969  5.533  1"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Importing packages and data\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import linear_model, metrics, preprocessing\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report,accuracy_score\n",
    "from sklearn.metrics import confusion_matrix,accuracy_score\n",
    "\n",
    "seeds = pd.read_csv('seeds_dataset.txt', delimiter='\\t', header = None)\n",
    "num_row, num_col = seeds.shape\n",
    "seeds.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "54e0bcfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Splitting train and test\n",
    "train = seeds.sample(frac=0.8, random_state=25)\n",
    "test = seeds.drop(train.index)\n",
    "\n",
    "C0 = seeds.copy()\n",
    "C1 = seeds.copy()\n",
    "C2 = seeds.copy()\n",
    "\n",
    "training_data_set = [C0, C1, C2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "cd6fe798",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(training_data_set)\n",
    "# len(training_data_set)\n",
    "# print(training_data_set[1])\n",
    "# print(training_data_set[i].at[4,7])\n",
    "\n",
    "for i in range(3):\n",
    "    for j in range(210):\n",
    "        if training_data_set[i].at[j,7] == i:\n",
    "#             print(\"i match: \", training_data_set[i].at[j,7])\n",
    "            training_data_set[i].at[j,7] = 1\n",
    "        else:\n",
    "#             print(\"i did not match: \", training_data_set[i].at[j,7])\n",
    "            training_data_set[i].at[j,7] = 0\n",
    "            \n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "8701d165",
   "metadata": {},
   "outputs": [],
   "source": [
    "datadict = {}  \n",
    "\n",
    "for i in range(3):\n",
    "    X = training_data_set[i].iloc[:,:7]\n",
    "    # min max scaling\n",
    "    min_max_scaler = preprocessing.MinMaxScaler()\n",
    "    X = min_max_scaler.fit_transform(X)\n",
    "    X = X.T\n",
    "    y = training_data_set[i].iloc[:,-1]\n",
    "    # y label encoding\n",
    "    lab = preprocessing.LabelEncoder()\n",
    "    y = lab.fit_transform(y)\n",
    "    y = np.array([y])\n",
    "    datadict['C'+str(i)] = [X,y]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "7c3b7030",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for dataset 0\n",
      "total iterations:  2830\n",
      "weight and bias for dataset 0\n",
      "[array([[-2.51374443, -0.85196054, -1.52723908, -0.31941916, -1.87426562,\n",
      "        -1.32041136,  0.14106833]]), -3.891952690082886]\n",
      "Training for dataset 1\n",
      "total iterations:  69750\n",
      "weight and bias for dataset 1\n",
      "[array([[ -4.27635418,   6.87350007,   4.09711272,  24.8793411 ,\n",
      "         -4.19071771,  -6.84636963, -32.82384848]]), 3.443587082903393]\n",
      "Training for dataset 2\n",
      "total iterations:  28990\n",
      "weight and bias for dataset 2\n",
      "[array([[ 4.81629084,  5.75340267, -1.5776131 , -1.86042682,  5.09029618,\n",
      "         4.80722565, 10.96756825]]), -13.993467305563486]\n"
     ]
    }
   ],
   "source": [
    "itterations = 100000   #random big value \n",
    "alpha = 0.160 \n",
    "m = 210\n",
    "cost_values = []\n",
    "trained_parameters = []\n",
    "\n",
    "for trainsets in range(3):\n",
    "  X = datadict['C'+str(trainsets)][0] \n",
    "  y = datadict['C'+str(trainsets)][1]\n",
    "  weights = np.random.randn(1,7)\n",
    "  bias = 0 \n",
    "  costfunc_values = []\n",
    "  k = 0\n",
    "  print('Training for dataset '+str(trainsets))\n",
    "  for i in range(1,itterations+1):\n",
    "    #logistic function\n",
    "    try: \n",
    "        z = np.dot(weights,X) + bias \n",
    "        hypothesis = 1/(1 + np.exp(-z)) \n",
    "        #cost function\n",
    "        j = 1/m*(-1*(np.sum(y*np.log(hypothesis) + (1-y)*np.log(1-hypothesis))))\n",
    "        costfunc_values.append(j)\n",
    "        k+=1\n",
    "        #gradient decent\n",
    "        dw =  1/m * np.dot(hypothesis-y,X.T)\n",
    "        db =  1/m * np.sum(hypothesis-y)\n",
    "        weights = weights - alpha*dw\n",
    "        bias = bias - alpha*db\n",
    "        if i%10 == 0:\n",
    "            if abs(j-costfunc_values[i-2])<0.000001:\n",
    "                if abs(j-costfunc_values[i-3])<0.000001:\n",
    "                    break \n",
    "    except:\n",
    "        continue\n",
    "  cost_values.append(costfunc_values)    \n",
    "  trained_parameters.append([weights,bias])\n",
    "  print(\"total iterations: \", i)\n",
    "  print(\"weight and bias for dataset\", trainsets)\n",
    "  print(trained_parameters[trainsets])\n",
    "\n",
    "    \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "3997db0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy for dataset 0  =  100.0\n",
      "accuracy for dataset 1  =  95.23809523809523\n",
      "accuracy for dataset 2  =  98.09523809523809\n"
     ]
    }
   ],
   "source": [
    "for datasetnum in range(3):\n",
    "  X = datadict['C'+str(datasetnum)][0]\n",
    "  y = datadict['C'+str(datasetnum)][1]\n",
    "  weights = trained_parameters[datasetnum][0]\n",
    "  bias = trained_parameters[datasetnum][1]\n",
    "  correct_predictions = 0 \n",
    "  for i in range(210):\n",
    "    z = np.dot(weights,X.T[i,:])+bias\n",
    "    hypothesis = 1/(1 + np.exp(-z))\n",
    "    if np.logical_and(hypothesis >= 0.5,y.T[i,0] == 1):\n",
    "        correct_predictions+=1\n",
    "    if np.logical_and(hypothesis < 0.5,y.T[i,0] == 0):\n",
    "        correct_predictions+=1    \n",
    "  #print(correct_predictions)      \n",
    "  acc = (correct_predictions/210)*100\n",
    "  print('accuracy for dataset '+str(datasetnum),\" = \",acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a89b2166",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "105b1f0b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
